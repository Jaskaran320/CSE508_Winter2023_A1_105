{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import lxml\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from typing import List, Dict, Tuple, Union\n",
    "import string\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "ORIGINAL_PATH = os.path.join(os.getcwd(), os.pardir, os.pardir, 'Dataset', 'CSE508_Winter2023_Dataset', 'CSE508_Winter2023_Dataset')\n",
    "ALTERED_PATH = os.path.join(os.getcwd(), 'DatasetAlter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alter(seed=1):\n",
    "\n",
    "\trandom.seed(seed)\n",
    "\trandom_samples = random.sample(range(1, 1401), 5)\n",
    "\n",
    "\tif not os.path.exists(ALTERED_PATH):\n",
    "\t\tos.makedirs(ALTERED_PATH)\n",
    "\n",
    "\tfor filename in os.listdir(ORIGINAL_PATH):\n",
    "\n",
    "\t\twith open(os.path.join(ORIGINAL_PATH, filename), 'r') as f:\n",
    "\t\t\toriginal = f.read()\n",
    "\n",
    "\t\tsoup = BeautifulSoup(original, 'lxml')\n",
    "\t\tcontent = soup.title.string.strip() + \" \" + soup.find('text').text.strip()\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"Filename: \", filename)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"Before: \")\n",
    "\t\t\tprint(original)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\twith open(os.path.join(ALTERED_PATH, filename), 'w') as fa:\n",
    "\t\t\tfa.write(content)\n",
    "\n",
    "\tprint(\"Finished Processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_alter():\n",
    "\tfor filename in os.listdir(ALTERED_PATH):\n",
    "\t\tos.remove(os.path.join(ALTERED_PATH, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_alter()\n",
    "create_alter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(seed=1):\n",
    "\trandom.seed(seed)\n",
    "\trandom_samples = random.sample(range(1, 1401), 5)\n",
    "\n",
    "\tfor filename in os.listdir(ALTERED_PATH):\n",
    "\t\twith open(os.path.join(ALTERED_PATH, filename), 'r') as f:\n",
    "\t\t\toriginal = f.read()\n",
    "\n",
    "\t\tcontent = original.lower()\n",
    "\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"LOWERCASE\")\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"Filename: \", filename)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"Before: \")\n",
    "\t\t\tprint(original)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\tcontent = word_tokenize(content)\n",
    "\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"TOKENIZE\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\tcontent = [w for w in content if not w in stopwords.words('english')]\n",
    "\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"STOPWORDS\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\tcontent = [w for w in content if not w in punctuation]\n",
    "\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"PUNCTUATION\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\tcontent = [w for w in content if w.strip()]\n",
    "\n",
    "\n",
    "\t\tif int(filename[-4:]) in random_samples:\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\t\t\tprint(\"BLANKSPACE\")\n",
    "\t\t\tprint(\"After: \")\n",
    "\t\t\tprint(content)\n",
    "\t\t\tprint(\"----------------------------------\")\n",
    "\n",
    "\t\tcontent = \" \".join(content)\n",
    "\n",
    "\t\twith open(os.path.join(ALTERED_PATH, filename), 'w') as fa:\n",
    "\t\t\tfa.write(content)\n",
    "\n",
    "\tprint(\"Finished Processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanQueries:\n",
    "    def __init__(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the BooleanQueries object.\n",
    "        :param path: The path to the collection of documents.\n",
    "        \"\"\"\n",
    "\n",
    "        self.docs: int = 0\n",
    "        self.index: Dict[str, Tuple[int, List[str]]] = {}\n",
    "        self.PATH: str = path\n",
    "        self.buildIndex()\n",
    "\n",
    "\n",
    "    def buildIndex(self) -> None:\n",
    "        \"\"\"\n",
    "        Build the inverted index by processing each document in the collection.\n",
    "        Process includes lower-casing, tokenizing, removing stopwords, punctuations and blank spaces.\n",
    "        \"\"\"\n",
    "\n",
    "        for filename in os.listdir(self.PATH):\n",
    "            self.docs += 1\n",
    "\n",
    "            with open(os.path.join(self.PATH, filename), 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            # Tokenize and lower case\n",
    "            tokens = word_tokenize(content.lower())\n",
    "            # Remove stopwords\n",
    "            tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "            # Remove punctuation\n",
    "            tokens = [token.translate(str.maketrans(\"\", \"\", string.punctuation)) for token in tokens]\n",
    "            # Remove blank spaces\n",
    "            tokens = [token for token in tokens if token.strip()]\n",
    "\n",
    "            # Add to index\n",
    "            for token in tokens:\n",
    "                if token not in self.index:\n",
    "                    self.index[token] = (0, [filename])\n",
    "                else:\n",
    "                    self.index[token][1].append(filename)\n",
    "\n",
    "            # Sort unique postings\n",
    "            for token in self.index:\n",
    "                self.index[token] = (len(self.index[token][1]), sorted(list(set(self.index[token][1]))))\n",
    "\n",
    "        print(\"Finished Building Index\")\n",
    "\n",
    "\n",
    "    def getPostingList(self, term: str) -> Tuple[int, List[str]]:\n",
    "        \"\"\"\n",
    "        Get the posting list for a term.\n",
    "        :param term: The term to get the posting list for.\n",
    "        :return: The posting list for the term as well as the frequency of the term in the collection.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.index[term] if term in self.index else (0, [])\n",
    "\n",
    "\n",
    "    def getTotalDocs(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the total number of documents in the collection.\n",
    "        :return: The total number of documents in the collection.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.docs\n",
    "\n",
    "\n",
    "    def queryAND(self, term1: Union[str, List[str]], term2: Union[str, List[str]]) -> Tuple[List[str], int]:\n",
    "        \"\"\"\n",
    "        Perform a boolean AND query on the inverted index.\n",
    "        :param term1: The first term to query or a posting list.\n",
    "        :param term2: The second term to query or a posting list.\n",
    "        :return: A list of document names that contain both terms and the number of comparisons made.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if terms are in inverted index\n",
    "        if not isinstance(term1, list) and term1 not in self.index:\n",
    "            return [], 0\n",
    "        if not isinstance(term2, list) and term2 not in self.index:\n",
    "            return [], 0\n",
    "        if isinstance(term1, list) and len(term1) == 0:\n",
    "            return [], 0\n",
    "        if isinstance(term2, list) and len(term2) == 0:\n",
    "            return [], 0\n",
    "\n",
    "        # Get posting lists\n",
    "        postings1 = self.index[term1][1] if isinstance(term1, str) else term1\n",
    "        postings2 = self.index[term2][1] if isinstance(term2, str) else term2\n",
    "\n",
    "        # Perform AND\n",
    "        comparisons = 0\n",
    "        result = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < len(postings1) and j < len(postings2):\n",
    "            comparisons += 1\n",
    "            if postings1[i] == postings2[j]:\n",
    "                result.append(postings1[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif postings1[i] < postings2[j]:\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "\n",
    "        return result, comparisons\n",
    "\n",
    "    def queryOR(self, term1: Union[str, List[str]], term2: Union[str, List[str]]) -> Tuple[List[str], int]:\n",
    "        \"\"\"\n",
    "        Perform a boolean OR query on the inverted index.\n",
    "        :param term1: The first term to query or a posting list.\n",
    "        :param term2: The second term to query or a posting list.\n",
    "        :return: A list of document names that contain both terms and the number of comparisons made.\n",
    "        \"\"\"\n",
    "\n",
    "        # Posting Lists\n",
    "        postings1 = []\n",
    "        postings2 = []\n",
    "\n",
    "        # Check if terms are in inverted index\n",
    "        if not isinstance(term1, list) and term1 not in self.index:\n",
    "            postings1.append(\"1\")\n",
    "        if not isinstance(term2, list) and term2 not in self.index:\n",
    "            postings2.append(\"1\")\n",
    "        if isinstance(term1, list) and len(term1) == 0:\n",
    "            postings1.append(\"1\")\n",
    "        if isinstance(term2, list) and len(term2) == 0:\n",
    "            postings2.append(\"1\")\n",
    "\n",
    "        # No merge if one of the lists is empty\n",
    "        if postings1 and not postings2:\n",
    "            return self.index[term2][1] if isinstance(term2, str) else term2, 0\n",
    "        elif postings2 and not postings1:\n",
    "            return self.index[term1][1] if isinstance(term1, str) else term1, 0\n",
    "        elif postings1 and postings2:\n",
    "            return [], 0\n",
    "\n",
    "        # Get posting lists\n",
    "        postings1 = self.index[term1][1] if isinstance(term1, str) else term1\n",
    "        postings2 = self.index[term2][1] if isinstance(term2, str) else term2\n",
    "\n",
    "        # Perform OR\n",
    "        comparisons = 0\n",
    "        result = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < len(postings1) and j < len(postings2):\n",
    "            comparisons += 1\n",
    "            if postings1[i] == postings2[j]:\n",
    "                result.append(postings1[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif postings1[i] < postings2[j]:\n",
    "                result.append(postings1[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(postings2[j])\n",
    "                j += 1\n",
    "\n",
    "        while i < len(postings1):\n",
    "            result.append(postings1[i])\n",
    "            i += 1\n",
    "\n",
    "        while j < len(postings2):\n",
    "            result.append(postings2[j])\n",
    "            j += 1\n",
    "\n",
    "        return result, comparisons\n",
    "\n",
    "\n",
    "    def queryNOT(self, term: Union[str, List[str]]) -> Tuple[List[str], int]:\n",
    "        \"\"\"\n",
    "        Perform a boolean OR query on the inverted index.\n",
    "        :param term: The term to query or a posting list.\n",
    "        :return: A list of document names that do not contain the term and the number of comparisons made.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all postings\n",
    "        all_postings = [filename for filename in os.listdir(self.PATH)]\n",
    "\n",
    "        # Check if term is in inverted index\n",
    "        if not isinstance(term, list) and term not in self.index:\n",
    "            return all_postings, 0\n",
    "        if isinstance(term, list) and len(term) == 0:\n",
    "            return all_postings, 0\n",
    "\n",
    "        # Get posting lists\n",
    "        postings = self.index[term][1] if isinstance(term, str) else term\n",
    "\n",
    "\n",
    "        # Perform NOT\n",
    "        comparisons = 0\n",
    "        result = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < len(postings) and j < len(all_postings):\n",
    "            comparisons += 1\n",
    "            if postings[i] == all_postings[j]:\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif postings[i] < all_postings[j]:\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(all_postings[j])\n",
    "                j += 1\n",
    "\n",
    "        while j < len(all_postings):\n",
    "            result.append(all_postings[j])\n",
    "            j += 1\n",
    "\n",
    "        return result, comparisons\n",
    "\n",
    "\n",
    "    def queryANDNOT(self, term1: Union[str, List[str]], term2: Union[str, List[str]]) -> Tuple[List[str], int]:\n",
    "        \"\"\"\n",
    "        Perform a boolean AND NOT query on the inverted index.\n",
    "        :param term1: The first term to query or a posting list.\n",
    "        :param term2: The second term to query or a posting list.\n",
    "        :return: A list of document names that contain term1 but not term2 and the number of comparisons made.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if terms are in inverted index\n",
    "        if not isinstance(term1, list) and term1 not in self.index:\n",
    "            return [], 0\n",
    "        if isinstance(term1, list) and len(term1) == 0:\n",
    "            return [], 0\n",
    "        if not isinstance(term2, list) and term2 not in self.index:\n",
    "            return self.index[term1][1] if isinstance(term1, str) else term1, 0\n",
    "        if isinstance(term2, list) and len(term2) == 0:\n",
    "            return self.index[term1][1] if isinstance(term1, str) else term1, 0\n",
    "\n",
    "        # Get posting lists\n",
    "        postings1 = self.index[term1][1] if isinstance(term1, str) else term1\n",
    "        postings2 = self.index[term2][1] if isinstance(term2, str) else term2\n",
    "\n",
    "        # Perform AND NOT\n",
    "        comparisons = 0\n",
    "        result = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < len(postings1) and j < len(postings2):\n",
    "            comparisons += 1\n",
    "            if postings1[i] == postings2[j]:\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif postings1[i] < postings2[j]:\n",
    "                result.append(postings1[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "\n",
    "        while i < len(postings1):\n",
    "            result.append(postings1[i])\n",
    "            i += 1\n",
    "\n",
    "        return result, comparisons\n",
    "\n",
    "\n",
    "    def queryProcess(self, query: str) -> Tuple[List[str], int]:\n",
    "        \"\"\"\n",
    "        Parse a query and perform the appropriate boolean query. Queries are performed in the order of NOT, AND, OR.\n",
    "        :param query: The query to parse, should be of the form \"A AND B OR NOT C AND NOT D\" or a similar combination.\n",
    "        :return: List of document names that match the query and the number of comparisons made.\n",
    "        \"\"\"\n",
    "\n",
    "        result = []\n",
    "        comparisons = 0\n",
    "\n",
    "        # Split query into OR subqueries\n",
    "        or_subqueries = query.split(\" OR \")\n",
    "\n",
    "        # Process each OR subquery\n",
    "        for subquery in or_subqueries:\n",
    "\n",
    "            # Tokenize subquery\n",
    "            subquery = [token for token in subquery.split(\" \") if token]\n",
    "\n",
    "            # If length is 1, simply perform OR query on the term\n",
    "            if len(subquery) == 1:\n",
    "                if not result:\n",
    "                    subresult = self.index[subquery[0]][1] if subquery[0] in self.index else []\n",
    "                    subcomparisons = 0\n",
    "                else:\n",
    "                    subresult, subcomparisons = self.queryOR(result, subquery[0])\n",
    "\n",
    "                result = subresult\n",
    "                comparisons += subcomparisons\n",
    "                continue\n",
    "\n",
    "            # Perform any NOT query at the start\n",
    "            elif subquery[0] == \"NOT\":\n",
    "                subresult, subcomparisons = self.queryNOT(subquery[1])\n",
    "                comparisons += subcomparisons\n",
    "                subquery = subquery[2:]\n",
    "\n",
    "                if not result:\n",
    "                    result = subresult\n",
    "                else:\n",
    "                    subresult, subcomparisons = self.queryOR(result, subresult)\n",
    "                    result = subresult\n",
    "                    comparisons += subcomparisons\n",
    "\n",
    "            # Parse rest of the query left to right\n",
    "            subresult = []\n",
    "            while subquery:\n",
    "\n",
    "                # Append term 1 to result\n",
    "                if subquery[0] != \"AND\" and not subresult:\n",
    "                    subresult = self.index[subquery[0]][1] if subquery[0] in self.index else []\n",
    "                    subquery = subquery[1:]\n",
    "                    continue\n",
    "\n",
    "                # Perform AND/AND NOT as required\n",
    "                if subquery[0] == \"AND\" and subquery[1] == \"NOT\":\n",
    "                    subresult, subcomparisons = self.queryANDNOT(subresult, subquery[2])\n",
    "                    comparisons += subcomparisons\n",
    "                    subquery = subquery[3:]\n",
    "\n",
    "                elif subquery[0] == \"AND\":\n",
    "                    subresult, subcomparisons = self.queryAND(subresult, subquery[1])\n",
    "                    comparisons += subcomparisons\n",
    "                    subquery = subquery[2:]\n",
    "\n",
    "            if not result:\n",
    "                result = subresult\n",
    "            else:\n",
    "                subresult, subcomparisons = self.queryOR(result, subresult)\n",
    "                result = subresult\n",
    "                comparisons += subcomparisons\n",
    "\n",
    "        return result, comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Boolean Queries ---\")\n",
    "print(\"Enter the full query: \")\n",
    "print()\n",
    "\n",
    "n = int(input(\"Enter the number of queries: \"))\n",
    "bq = BooleanQueries(os.path.join(os.getcwd(), 'DS2'))\n",
    "\n",
    "for i1 in range(n):\n",
    "    print(\"Enter the search term: \")\n",
    "    search_term = input()\n",
    "    print(\"Enter operations: \")\n",
    "    operations = input()\n",
    "\n",
    "\n",
    "    search_term = word_tokenize(search_term.lower())\n",
    "    search_term = [s for s in search_term if s not in stopwords.words(\"english\")]\n",
    "    search_term = [s.translate(str.maketrans(\"\", \"\", string.punctuation)) for s in search_term]\n",
    "    search_term = [s for s in search_term if s.strip()]\n",
    "\n",
    "    if operations:\n",
    "        operations = [s.strip() for s in operations.split(\",\")]\n",
    "        operations = [s for s in operations if s in [\"AND\", \"OR\", \"OR NOT\", \"AND NOT\"]]\n",
    "\n",
    "    if len(search_term) == 0 or len(operations) != len(search_term) - 1:\n",
    "        print(\"Invalid query\")\n",
    "        continue\n",
    "\n",
    "    query1 = \"\"\n",
    "    for j1 in range(len(search_term)):\n",
    "        query1 += search_term[j1]\n",
    "        if j1 < len(operations):\n",
    "            query1 += \" \" + operations[j1] + \" \"\n",
    "\n",
    "    print(\"Query: \", query1)\n",
    "\n",
    "    # query = query.replace(\"AND NOT\", \"ANDNOT\")\n",
    "\n",
    "    result1, comparisons1 = bq.queryProcess(query1)\n",
    "    print(\"Result: \", result1)\n",
    "    print(\"Frequency: \", len(result1))\n",
    "    print(\"Comparisons: \", comparisons1)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
