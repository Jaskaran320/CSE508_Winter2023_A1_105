{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import lxml\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from typing import List, Dict, Tuple, Union\n",
    "import string\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "ORIGINAL_PATH = os.path.join(os.getcwd(), 'Dataset')\n",
    "ALTERED_PATH = os.path.join(os.getcwd(), 'DatasetAlter')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "word_list = ['Number', 'of', 'words', 'in', 'a', 'document', 'is', 'not', 'fixed', 'and', 'can', 'vary', 'from', 'document', 'to', 'document', 'but', 'the',\n",
    "\t\t\t 'average', 'number', 'of', 'words', 'in', 'a', 'document', 'is', 'around', '200', 'to', '300', 'words', 'and', 'the', 'maximum', 'number', 'of', 'words', 'in', 'a', 'document', 'is', 'around', '1000', 'words']\n",
    "path = os.path.join(os.getcwd(), 'DS2')\n",
    "for i2 in range(10):\n",
    "\trandom.seed(i2)\n",
    "\trandom_indexes = random.sample(range(0, len(word_list)), 10)\n",
    "\tfilename1 = \"a\" + str(i2+1).zfill(2)\n",
    "\n",
    "\twith open(os.path.join(path, filename1), 'w') as f:\n",
    "\t\tfor j2 in random_indexes:\n",
    "\t\t\tf.write(word_list[j2] + \" \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BigramIndex:\n",
    "\tdef __init__(self, path: str) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize the BigramIndex object.\n",
    "\t\t:param path: The path to the collection of documents.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tself.docs: int = 0\n",
    "\t\tself.index: Dict[str, Tuple[int, List[str]]] = {}\n",
    "\t\tself.PATH: str = path\n",
    "\t\tself.buildIndex()\n",
    "\n",
    "\n",
    "\tdef buildIndex(self) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild the bigram inverted index by processing each document in the collection.\n",
    "\t\tProcess includes lower-casing, tokenizing, removing stopwords, punctuations and blank spaces.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tfor filename in os.listdir(self.PATH):\n",
    "\t\t\tself.docs += 1\n",
    "\n",
    "\t\t\twith open(os.path.join(self.PATH, filename), 'r') as f:\n",
    "\t\t\t\tcontent = f.read()\n",
    "\n",
    "\t\t\t# Tokenize and lower case\n",
    "\t\t\ttokens = word_tokenize(content.lower())\n",
    "\t\t\t# Remove stopwords\n",
    "\t\t\ttokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "\t\t\t# Remove punctuation\n",
    "\t\t\ttokens = [token.translate(str.maketrans(\"\", \"\", string.punctuation)) for token in tokens]\n",
    "\t\t\t# Remove blank spaces\n",
    "\t\t\ttokens = [token for token in tokens if token.strip()]\n",
    "\n",
    "\t\t\t# Add biwords to index\n",
    "\t\t\tfor b in range(len(tokens) - 1):\n",
    "\t\t\t\tbiword = tokens[b] + \" \" + tokens[b+1]\n",
    "\t\t\t\tif biword not in self.index:\n",
    "\t\t\t\t\tself.index[biword] = (0, [filename])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.index[biword][1].append(filename)\n",
    "\n",
    "\t\t\t# Sort unique postings\n",
    "\t\t\tfor token in self.index:\n",
    "\t\t\t\tself.index[token] = (len(self.index[token][1]), sorted(list(set(self.index[token][1]))))\n",
    "\n",
    "\t\tprint(\"Finished Building Index\")\n",
    "\n",
    "\n",
    "\tdef getPostingList(self, term: str) -> Tuple[int, List[str]]:\n",
    "\t\t\"\"\"\n",
    "\t\tGet the posting list for a term.\n",
    "\t\t:param term: The term to get the posting list for.\n",
    "\t\t:return: The posting list for the term as well as the frequency of the term in the collection.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\treturn self.index[term] if term in self.index else (0, [])\n",
    "\n",
    "\tdef singleWordPostingList(self, term: str) -> Tuple[int, List[str]]:\n",
    "\t\t\"\"\"\n",
    "\t\tGet the posting list for a term.\n",
    "\t\t:param term: The term to get the posting list for.\n",
    "\t\t:return: The posting list for the term as well as the frequency of the term in the collection.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tposting_list = []\n",
    "\t\t# Search all keys in index which contain the term and append the posting list to the list\n",
    "\t\tfor key in self.index:\n",
    "\t\t\tif term in key:\n",
    "\t\t\t\tposting_list.append(self.index[key][1])\n",
    "\n",
    "\t\t# Sort unique postings\n",
    "\t\tposting_list = sorted(list(set(posting_list)))\n",
    "\n",
    "\t\treturn len(posting_list), posting_list\n",
    "\n",
    "\n",
    "\tdef getTotalDocs(self) -> int:\n",
    "\t\t\"\"\"\n",
    "\t\tGet the total number of documents in the collection.\n",
    "\t\t:return: The total number of documents in the collection.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\treturn self.docs\n",
    "\n",
    "\n",
    "\tdef queryAND(self, term1: Union[str, List[str]], term2: Union[str, List[str]]) -> Tuple[List[str], int]:\n",
    "\t\t\"\"\"\n",
    "\t\tPerform a boolean AND query on the bigram inverted index.\n",
    "\t\t:param term1: The first term to query or a posting list.\n",
    "\t\t:param term2: The second term to query or a posting list.\n",
    "\t\t:return: A list of document names that contain both terms and the number of comparisons made.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# Check if terms are in inverted index\n",
    "\t\tif not isinstance(term1, list) and term1 not in self.index:\n",
    "\t\t\treturn [], 0\n",
    "\t\tif not isinstance(term2, list) and term2 not in self.index:\n",
    "\t\t\treturn [], 0\n",
    "\t\tif isinstance(term1, list) and len(term1) == 0:\n",
    "\t\t\treturn [], 0\n",
    "\t\tif isinstance(term2, list) and len(term2) == 0:\n",
    "\t\t\treturn [], 0\n",
    "\n",
    "\n",
    "\t\tpostings1 = self.index[term1][1] if isinstance(term1, str) else term1\n",
    "\t\tpostings2 = self.index[term2][1] if isinstance(term2, str) else term2\n",
    "\n",
    "\t\t# Perform AND\n",
    "\t\tcomparisons = 0\n",
    "\t\tresult = []\n",
    "\t\ti = 0\n",
    "\t\tj = 0\n",
    "\t\twhile i < len(postings1) and j < len(postings2):\n",
    "\t\t\tcomparisons += 1\n",
    "\t\t\tif postings1[i] == postings2[j]:\n",
    "\t\t\t\tresult.append(postings1[i])\n",
    "\t\t\t\ti += 1\n",
    "\t\t\t\tj += 1\n",
    "\t\t\telif postings1[i] < postings2[j]:\n",
    "\t\t\t\ti += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tj += 1\n",
    "\n",
    "\t\treturn result, comparisons\n",
    "\n",
    "\n",
    "\tdef queryProcess(self, query: str) -> Tuple[List[str], int]:\n",
    "\t\t\"\"\"\n",
    "\t\tParse a query and perform the appropriate boolean query. Only AND query is supported.\n",
    "\t\t:param query: The query to parse, should be of the form \"A B AND B C AND C D\" or a similar combination.\n",
    "\t\t:return: List of document names that match the query and the number of comparisons made.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tresult = []\n",
    "\t\tcomparisons = 0\n",
    "\n",
    "\t\t# Split query into AND subqueries\n",
    "\t\tand_subqueries = query.split(\" \")\n",
    "\n",
    "\t\tif len(and_subqueries) == 1:\n",
    "\t\t\treturn self.singleWordPostingList(and_subqueries[0])[1], 0\n",
    "\n",
    "\t\tbigram_subqueries = []\n",
    "\t\tfor s in range(len(and_subqueries) - 1):\n",
    "\t\t\tbigram_subqueries.append(and_subqueries[s] + \" \" + and_subqueries[s+1])\n",
    "\n",
    "\t\t# Process each AND subquery\n",
    "\t\tfor subquery in bigram_subqueries:\n",
    "\t\t\t# If result is empty, get posting list for first term\n",
    "\t\t\tif len(result) == 0:\n",
    "\t\t\t\tresult = self.index[subquery][1] if subquery in self.index else []\n",
    "\t\t\t\tcomparisons += 0\n",
    "\t\t\t# Otherwise, perform AND query\n",
    "\t\t\telse:\n",
    "\t\t\t\tresult, subcomparisons = self.queryAND(result, subquery)\n",
    "\t\t\t\tcomparisons += subcomparisons\n",
    "\n",
    "\t\treturn result, comparisons\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
